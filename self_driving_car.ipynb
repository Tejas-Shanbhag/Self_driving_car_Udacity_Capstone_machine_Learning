{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   SELF DRIVING CAR - UDACITY CAPSTONE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this project the aim is build a deep learning model using Keras to create a simulation for self driving car.The model should be able to accurately predict the steering angles by using the image of the road infront of the car as input. The model should be able to take a turn accurately depending upon the curvature of the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary modules \n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The next step is to import the dataset.The dataset consistes of about 45,000 images captured by the camer while the car was driven.It also includes a text file containing the image number and the steering angle recorded for that particular image depending upon the curvature of the road.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the dataset  consisting of the images\n",
    "pi = 3.14159265\n",
    "path = r\"driving_dataset/data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while importing the data we convert the value of degree to radians by multiplying it with (180/pi)\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "with open(path,'r') as f:\n",
    " for value in f:\n",
    "  x.append('driving_dataset/'+value.strip().split()[0])\n",
    "  y.append(round(float(value.strip().split()[1]) *(pi/180), 8 ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['driving_dataset/0.jpg',\n",
       " 'driving_dataset/1.jpg',\n",
       " 'driving_dataset/2.jpg',\n",
       " 'driving_dataset/3.jpg',\n",
       " 'driving_dataset/4.jpg',\n",
       " 'driving_dataset/5.jpg',\n",
       " 'driving_dataset/6.jpg',\n",
       " 'driving_dataset/7.jpg',\n",
       " 'driving_dataset/8.jpg',\n",
       " 'driving_dataset/9.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize  first 10 items in x\n",
    "x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize  first 10 steering angles in y\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  now we divide the data into training and testing sets with 20% of data going  into test set.However in this case we cannot \n",
    "#  split the data randomly and we need to follow the same order\n",
    "split_index= int(len(x)*0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We split the data into training and testing set using the split index.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:split_index]\n",
    "y_train = y[:split_index]\n",
    "x_test = x[split_index:]\n",
    "y_test = y[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the number of training Examples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36324"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of exaples in train set\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the number of Train labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36324"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of exaples in train set\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the number of test Examples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9082"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of exaples in test set\n",
    "len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the number of test labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9082"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of exaples in test set\n",
    "len(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So the given data has been effectively divided into training and test data with 80% of the data going into training and the remaining 20% of the data going into the test set .We the train can clearly see that the train set has 36,324 examples and the test set has 9082 examples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then perform some exploratory data analysis to find the range anf frequency ditribution of our sterring angles.The best way to visualize a frequency distribution is by plotting a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269c7affda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram using values of steering angles.\n",
    "plt.hist(y ,normed=True, bins=100)\n",
    "plt.xlabel(\"Angle in radians\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Next we need to create the Neural Network model and train the network on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"cnnn.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above architecture was designed by Nvidia specially for training model for self driving cars.Its an very effecient model which was designed and the best part is the CNN Performs extremely well inspite of having no pooling or dropout layers .**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ts111\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import all the necessary libraries for building the model using keras\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters =24 , kernel_size =5, strides =2 ,padding = 'valid' ,activation = 'relu' , input_shape=(66,200,3)))\n",
    "model.add(Conv2D(filters =36 , kernel_size =5 , strides =2 ,padding ='valid' ,activation = 'relu' ))\n",
    "model.add(Conv2D(filters =48 , kernel_size =5 ,strides =2 ,padding = 'valid' ,activation = 'relu' ))\n",
    "model.add(Conv2D(filters =64 , kernel_size =3 ,strides =1 ,padding = 'valid' ,activation = 'relu' ))\n",
    "model.add(Conv2D(filters =64 , kernel_size =3 ,strides =1 ,padding = 'valid' ,activation = 'relu' ))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1164 ,activation ='relu'))\n",
    "model.add(Dense(100 ,activation ='relu'))\n",
    "model.add(Dense(50 ,activation ='relu'))\n",
    "model.add(Dense(10 ,activation ='relu'))\n",
    "model.add(Dense(1 ,activation ='tanh'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1164)              1342092   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,595,511\n",
      "Trainable params: 1,595,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The next important step is to convert the images into tensors so that it can be fed as an input to the neural network .Out x_train consists of a list where each element of the list is a string consisting of the image path.We need to write a function that gets the image from the path and the converts the image to an appropriate dimension so that it can be effectively fed to the neural network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "def path_to_tensor(img_path):\n",
    "    img = image.load_img(img_path, target_size=(66, 200))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (66, 200, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_tensors = paths_to_tensor(x_train[0:18000]).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensors = paths_to_tensor(x_test).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finally we use Adam as the optimizer and because we need to find the deviation between the predicted value and the true value we use mean squared error as the accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-4), loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_model_new/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "histor =model.fit(train_tensors, y_train[:18000], \n",
    "          validation_data=(test_tensors, y_test),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)\n",
    "plt.plot(histor.history['mean_squared_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean squared error with for 20 epochs\n",
    "# this result was obtained when initially the model was run for 20 epochs\n",
    "plt.plot(histor.history['mean_squared_error'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error after 50 epochs\n",
    "plt.plot(histor.history['mean_squared_error'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_model_new/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the predictions of the first ten angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "angle_predictions = [(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we visualize our model using openCV2 module. First each of the image in the dataset is displayed along with the actual rotation of the steering wheel based on the prediction angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.misc\n",
    "import cv2\n",
    "from subprocess import call\n",
    "from keras.preprocessing import image  \n",
    "\n",
    "img = cv2.imread('ferrari.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "# starting from the 100 image\n",
    "i = 150\n",
    "while(cv2.waitKey(10) != ord('x') ):\n",
    "    real_image = scipy.misc.imread(\"driving_dataset/\" + str(i) + \".jpg\", mode=\"RGB\")\n",
    "    fulll_image = image.img_to_array(image.load_img('driving_dataset/'+str(i)+ '.jpg',target_size=(66, 200)))\n",
    "    images = np.expand_dims(fulll_image, axis=0) / 255.0\n",
    "    degrees = model.predict(images)[0] *(180.0 / scipy.pi)\n",
    "    call(\"clear\")\n",
    "    print(\"The Predicted steering angle is: \" + str(degrees) + \" degrees\")\n",
    "    cv2.imshow(\"frame\", cv2.cvtColor(real_image, cv2.COLOR_RGB2BGR))\n",
    "    smoothed_angle += 0.2 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"Steering Wheel\", dst)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
